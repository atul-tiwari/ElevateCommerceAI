{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1831"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('asin_list.pickle', 'rb') as f:\n",
    "    asin_list = pickle.load(f)\n",
    "\n",
    "len(asin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "休闲零食.pickle 3\n",
      "冲调.pickle 3\n",
      "南北干货.pickle 3\n",
      "咖啡及可可.pickle 3\n",
      "方便食品.pickle 3\n",
      "水饮、乳品、果汁.pickle 3\n",
      "烘焙.pickle 3\n",
      "米面杂粮.pickle 3\n",
      "糕点饼干.pickle 3\n",
      "糖果、巧克力.pickle 3\n",
      "节日、礼盒、礼券.pickle 3\n",
      "茶.pickle 3\n",
      "调味佐料.pickle 3\n",
      "酒.pickle 3\n",
      "食用油.pickle 3\n",
      "鲜花.pickle 3\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n",
      "category_name\n",
      "category_url\n",
      "data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, os, pickle\n",
    "product_list = []\n",
    "\n",
    "os.chdir(r\"H:\\w_crawler\\Amazon China Food\\data\")\n",
    "for file in glob.glob(\"*.pickle\"):\n",
    "    with open(file, 'rb') as f:\n",
    "        item = pickle.load(f)\n",
    "        product_list.extend(item)\n",
    "        print(file,len(item))\n",
    "\n",
    "product_dict = {}\n",
    "for prod in product_list:\n",
    "    try:\n",
    "        product_dict[prod['ASIN']] = prod\n",
    "    except:\n",
    "        print(prod)\n",
    "\n",
    "len(product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"H:\\w_crawler\\Amazon China Food\\data\\糕点饼干.pickle\", 'rb') as f:\n",
    "    item = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asin_list = list(set(asin_list) - set(product_dict.keys()))\n",
    "len(asin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'H:\\Amazon China Food\\asin_list.pickle', 'wb') as f:\n",
    "    pickle.dump(asin_list, f)\n",
    "\n",
    "with open(r'H:\\Amazon China Food\\prod_list_2k.pickle', 'wb') as f:\n",
    "    pickle.dump(product_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_list_10k.pickle 9895\n",
      "prod_list_11k.pickle 11603\n",
      "prod_list_2k.pickle 1796\n",
      "prod_list_8k.pickle 7993\n",
      "prod_list_9k.pickle 9422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40686"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, os\n",
    "product_dict = {}\n",
    "\n",
    "os.chdir(r\"H:\\Amazon China Food\\product data\\prod_dict\")\n",
    "for file in glob.glob(\"*.pickle\"):\n",
    "    with open(file, 'rb') as f:\n",
    "        item = pickle.load(f)\n",
    "        product_dict.update(item)\n",
    "        print(file,len(item))\n",
    "\n",
    "len(product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"H:\\Amazon China Food\\data\\Amazon_China_Food.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          46697\n",
       "unique         40712\n",
       "top       B0116U7ZYG\n",
       "freq               4\n",
       "Name: product_id, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.product_id.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manu (prod_id):\n",
    "    try:\n",
    "        return product_dict.get(prod_id,None).get(\"制造商\",None)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Manufacturer'] = df['product_id'].apply(lambda x: get_manu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"H:\\Amazon China Food\\Amazon_China_Food.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"H:\\w_crawler\\Amazon China Food\\data\\Amazon_China_Food.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = list(df['product_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def Clean(text):\n",
    "    text = text.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\"\\r\",\"\")\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,random\n",
    "response = requests.get(f\"https://proxy.webshare.io/api/v2/proxy/list/?mode=direct&page={random.randint(1,5)}&page_size=50\", headers={\"Authorization\": \"94a3056cb6e4d13ef5b61adbb44c8b99d2f9aef4\"})\n",
    "data_dict = response.json()\n",
    "proxy_list = list(map(lambda x: f\"http://{x['username']}:{x['password']}@{x['proxy_address']}:{x['port']}\",data_dict['results']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'text/html,*/*',\n",
    "    'Accept-Language': 'en-US,en;q=0.9,ja;q=0.8',\n",
    "    'Connection': 'keep-alive',\n",
    "    'DNT': '1',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    'downlink': '2.1',\n",
    "    'ect': '4g',\n",
    "    'rtt': '100',\n",
    "    'sec-ch-ua': '\"Chromium\";v=\"110\", \"Not A(Brand\";v=\"24\", \"Google Chrome\";v=\"110\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-ch-ua-platform-version': '\"10.0.0\"',\n",
    "}\n",
    "\n",
    "def get_rating_data(ASIN):\n",
    "    params = {\n",
    "    'ie': 'UTF8',\n",
    "    'asin': ASIN,\n",
    "    'ref': 'acr_search__popover',\n",
    "    'contextId': 'search',\n",
    "    }\n",
    "    proxy = random.choice(proxy_list)\n",
    "    s_proxy_dict = {\"http\": proxy, 'https': proxy}\n",
    "\n",
    "    response = requests.get(\n",
    "        'https://www.amazon.cn/review/widgets/average-customer-review/popover/ref=acr_search__popover',\n",
    "        params=params,\n",
    "        headers=headers,\n",
    "        proxies=s_proxy_dict\n",
    "    )\n",
    "    dom = lxml.html.fromstring(response.text)\n",
    "    data_dict = {}\n",
    "    data_dict['ASIN'] = ASIN\n",
    "    stars = dom.xpath('//div[@role=\"progressbar\"]/@aria-valuenow')\n",
    "\n",
    "    for i in range(5,0,-1):\n",
    "        data_dict[f'{i}_Stars']=stars[5-i]\n",
    "\n",
    "    totalRatingCount = dom.xpath('//span[contains(@class,\"totalRatingCount\")]/text()')[0]\n",
    "    data_dict[\"totalRatingCount\"] = Clean(totalRatingCount.replace(\"买家评级\",\"\"))\n",
    "\n",
    "    rating = dom.xpath('//span[contains(@data-hook,\"acr-average\")]/text()')[0]\n",
    "    data_dict[\"rating\"] = Clean(rating.replace(\"星，共 5 星\",\"\"))\n",
    "    return data_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ASIN': 'B094VXYXBT',\n",
       " '5_Stars': '52%',\n",
       " '4_Stars': '13%',\n",
       " '3_Stars': '0%',\n",
       " '2_Stars': '0%',\n",
       " '1_Stars': '35%',\n",
       " 'totalRatingCount': '12',\n",
       " 'rating': '3.5'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rating_data('B094VXYXBT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "result =[]\n",
    "with ThreadPoolExecutor(max_workers=12) as exe:\n",
    "    exe.submit(get_rating_data,2)\n",
    "        \n",
    "    # Maps the method 'cube' with a list of values.\n",
    "    result = exe.map(get_rating_data,products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle generator objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9772\\582251693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'amazon_start_data.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle generator objects"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('amazon_start_data.pickle', 'wb') as handle:\n",
    "    pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data = list(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"H:\\w_crawler\\Amazon China Food\\data\\Amazon_China_Food.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B07NFQH21P', 'B07WWHV4QW', 'B00442TL32', ..., 'B00YC0N3ZI',\n",
       "       'B00R0KV73M', 'B002FTM3LI'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['product_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'H:\\w_crawler\\Amazon China Food\\asin_list.pickle', 'wb') as f:\n",
    "    pickle.dump(list(df['product_id'].unique()), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w_crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5500c02fbb5ad642ab7d07d8a7d943becb875e66bcb2c04d28d32e64be642486"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
